\chapter{Implementation}
\todo{Explain rust compiler plugin types. Why we compile twice, etc.}
\todo{Justify all decisions. Explain alternatives considered/implemented and why the design changed}

This chapter looks at how the design was implemented in practice and the design decisions that had to be adapted due to unforeseen complexities. \todo{pad}

There was three choices on how I could implement the design: directly modifying the rust compiler source code and recompiling the compiler; using the rust compiler plugin system to modify the abstract syntax tree or writing a source to source translation from scratch. Modifying the rust compiler would give me the flexibility to change any part of the compiler that I needed but it would make seeing my individual contributions difficult. Also, the compiler itself is very large and complex; it would take a while to compile from a clean state. Using a rust compiler plugin would give me less access, but I would only need to compile my plugin. The complexity of the compiler is still there with this option. Writing a source to source translation system from scratch would allow me to avoid touching the rust compiler and it's complexity. In return, I would have to write code to extract the abstract syntax tree from a source file. I would have to model the ownership/borrowing information to detect when parallelisms properly. From all these choices, I decided to write a rust compiler plugin as it provides all the ownership information is already accessibly. This option will require me to use the full abstract syntax tree; the other options had the possibility of using the less verbose high-level intermediate representation (basically syntax sugar free rust code).


The rust compiler allows for plugins of different types. The two types of plugins used are Syntax Extension plugin and a Linter Plugin. Syntax Extension plugins are run first, and are generally used to convert macros into code. I will use a syntax extension to change the entire body of a function from sequential code into parallelised code. Linter plugins run after all the syntax extension plugins, and are generally used to check code style to produce warnings (like unused variable).

The linter plugin will have the abstract syntax tree of the code with all the macros expanded. This stage has all the information required about dependencies. However, once the rust compiler gets to the linter plugins, I can no longer edit the code (without recompiling the compiler). The solution I decided on was to compile the program twice. On the first compile, the syntax extension does nothing and the linter plugin examines the expanded code. The dependency information gathered is saved into a file for the next compile. On the second compile, the syntax extension plugin reads the file to get all the dependency information. Any parallelisable parts are modified to be run in parallel.

The rust plugin system requires an annotation to be able to access that element of the code. Each function of the sequential source code should be annotated with \texttt{\#[autoparallelise]}. The AST is described by three types of structs: Block, Stmt and Expr. A block contains a list of statements, and each statement is a combination of expressions. Macros can take arguments and are transformed into code. This transformation happens in the compiler after executing all the syntax extension plugins. Each function is evaluated separately.

\section{Dependency Analysis}
The dependency analysis stage is split over two compiles. The first compile uses the linter plugin, and the second uses the syntax extension plugin.

\subsection{Linter Plugin}
% Analysis Stage
%==================
% Convert from Rust AST to our representation of Blocks and Statements
% Examine each statement for variables
% Find out the previous statement that the variable is referenced.
% This is a dependency and recorded as a relative id for the block
% Inside a block, a new DependencyTree is created
% The function name, DependencyTree and some other meta data is stored into an list.
% This is repeated for all the functions which have the annotation

% Once all the function have been analysed.
% Each dependency tree is converted into an EncodedDependencyTree by taking the StmtID of each statement.
% StmtID is the span.lo().0 and span.hi().0 which refers to the byte in the original source code.

% All the EncodedDependencyTree's and function meta data is saved into a JSON file
The block of the sequential function is examined statement by statement. Each statement is converted into our representation of the AST so that information can be stored about the dependencies. The extra information includes two environments containing which variables the statement requires and produces.

Once all the statements for a function are converted into our representation, the dependency environment need to be matched up to statement ids. Each converted statement is looked at in turn, starting from the beginning of the function. The algorithm looks backwards from the current point in the function to find what statements produce the variables in the requires environment. The statement ID relative to the block of all of the dependencies is stored as part of the converted statement.

It is possible for a block to be inside a block by being represented as a Statement. Blocks need to be evaluated using the same method as explained in the previous paragraph. A block statement is represented as a list of converted statements, as well as the blocks own environment and dependency ids. It is also possible for a new block to be part of another expression (i.e. for loops). In this case, this is stored as an ExprBlock with the statement that the block originates from, a subtree containing a Block statement (there could be more than one block) and the environments/dependency ids.

Once all functions have been analysed, the DependencyTree is converted into an EncodedDependencyTree. The code part of the converted statement is converted into a statement id. The statement ID is represented as a pair of numbers \texttt{(span.lo().0, span.hi().0)}, which relate to the byte location of the source code. This will remain consistent between compile runs, whereas the NodeID does not. All EncodedDependencyTrees and function meta data is stored into a JSON file using \texttt{serde\_json}.


\subsection{Syntax Extension Plugin}
% Modification Stage
%==================
% First part of analysis stage is repeated for the modification stage.
% Modification stage does not have marcos expanded, and so some dependencies would be missed.
% The EncodedDependencyTree is loaded from the JSON file which should include the dependency of the expanded macros.
% The EncodedDependencyTree is merged with the DependencyTree from the Modification stage so that unexpanded macros have dependencies.

The plugin detects the JSON file and loads it. This is stored as a shared state between different functions.

The first part of the dependency analysis is repeated for the syntax extension plugin this time. In later section of the design, we need access to the pure AST. There is no (easy) way for the AST to be store into a JSON file and recreated into structs that I could find. The reason that we use the linter plugin is so that we can see the dependencies hidden inside macros.

The dependencies are merged function by function from the shared state so that unexpanded macros get the missing dependencies. The dependencies of Statements that have the same StmtID are merged together.

\section{Scheduler}
% Takes the DependencyTree of a function with all relative dependencies added.
% Converts the relative dependencies into StmtIDs
% Maximum Spanning Tree:
% 	Looks for any fully independent statements and starts a new ScheduleTree for each of them
% 	while remaining_nodes:
%		For all remaining nodes:
%			if the node has all it's dependencies on the tree already
%				find dependency node with maximum performance value (+ all dependent nodes on tree)
%				add node to tree here (with a preresquite of all the other dependencies)
%				add synclines onto the other dependency nodes so that all dependencies will be met
% Inside a block, a new Schedule is created

% Performance Metric:
% Currently just a fixed number 1

Once the dependency analysis is complete, the scheduler takes the dependency tree and works out a schedule. All relative dependency ids are converted into StmtIDs. The idea around the scheduling algorithm is Maximum Spanning Trees. All statements that have no dependencies can be started at the very beginning. All remaining statements wait for all their dependencies to be put into the schedule. Once all the dependencies for a statement are added, this statement is selected as the next one to add to the schedule. As each statement requires all of its dependencies before it can be executed, it should be scheduled to run after the slowest dependency. This should minimise the amount of time that the statement has to wait for its dependencies. Synclines are created for all the remaining dependencies so that all dependencies are met. Each block gets its own schedule.

\section{Reconstructor}
All parts of the reconstructor algorithm takes part in the second compile.
% Takes the schedule of a function and converts it back into real (parallelised) code


\todo{Remove}
\section{Sample code section}

Here is some text above

%\begin{code}
%    % Sample code
%    \inputcode{autoparallelise/src/syntax_extension.rs}{50}{60}
%    \caption{}
%\end{code}

\begin{code}
    % FnKind Enum
    \inputcode{rust/src/libsyntax/visit.rs}{34}{43}
    \caption{}
\end{code}

\begin{code}
    % Block Struct
    \inputcode{rust/src/libsyntax/ast.rs}{489}{497}
    \caption{}
\end{code}

\begin{code}
    % Stmt Struct
    \inputcode{rust/src/libsyntax/ast.rs}{781}{785}
    \caption{}
\end{code}

\begin{code}
    % StmtKind enum
    \inputcode{rust/src/libsyntax/ast.rs}{815}{828}
    \caption{}
\end{code}


\begin{code}
\begin{minted}{rust}
let a; // Local without init
a = {
    let b = vec![1,2,3]; // Local with init
    println!("{:?}", b); // Mac
    b.len() // Expr
}; // Semi
\end{minted}
\caption{Example showing different StmtKinds}
\end{code}


\begin{code}
    % ExprKind enum
    \inputcode{rust/src/libsyntax/ast.rs}{987}{1122}
    \caption{}
\end{code}

\begin{code}
    % SpanData Struct
    \inputcode{rust/src/libsyntax_pos/lib.rs}{143}{149}
    \caption{}
\end{code}

Here is some text below \autoref{code:removeme}

\chapter{Implementation}
\label{chapter:Implementation}
%\todo{Justify all decisions. Explain alternatives considered/implemented and why the design changed}

This chapter looks at how the design was implemented in practice and the design decisions that had to be adapted due to unforeseen complexities. Each design change is justified with an example of why the original design fails, and alternatives that were considered.

\section{How to implement the design}
There was three choices on how I could implement the design: directly modifying the rust compiler source code and recompiling the compiler; using the rust compiler plugin system to modify the abstract syntax tree (AST) or writing a source to source translation from scratch. Modifying the rust compiler would give me the flexibility to change any part of the compiler that I needed but it would make seeing my individual contributions very difficult. Also, the compiler itself is very large and complex; it would take a while to compile from a clean state. Using a rust compiler plugin would give me less access, but I would only need to compile my plugin. The complexity of the compiler is still there with this option. Writing a source to source translation system from scratch would allow me to avoid touching the rust compiler and it's complexity. In return, I would have to write code to extract the AST from a source file. I would have to model the ownership/borrowing information to detect when parallelisms properly. From all these choices, I decided to write a rust compiler plugin as it provides all the ownership information is already accessibly. This option requires me to use the full AST; the other options had the possibility of using the less verbose high-level intermediate representation (HIR).

The rust compiler allows for plugins of different types. The two types of plugins of interest are Syntax Extension plugins and Linter plugins. Syntax Extension plugins are executed first in the rust compiler pipeline, and are generally used to convert macros into code. Linter plugins are run at a later stage, and are generally used to check code style to produce warnings (like unused variable). It has the complete AST of the code with all the macros expanded. All the information required about dependencies is accessible inside a linter plugin. However, once the rust compiler gets to the linter plugins, the AST can no longer be modified. Syntax extension plugins allow modification of the AST, but they do not have macros expanded. Some dependencies could be missed by trying to analyse the AST at this stage. The solution I decided on was to compile the program twice. On the first compile, the syntax extension does nothing and the linter plugin examines the expanded code. The dependency information gathered is saved into a file for the next compile. On the second compile, the syntax extension plugin reads the file to get all the dependency information. Any parallelisable parts are then modified to be run in parallel.

To use the rust plugin system, the source code will need to be annotated which provides the plugins with access to that element in the AST. Each function of the sequential source code should be annotated with \texttt{\#[autoparallelise]}. This annotation does not provide any information about the parallelisability of the source code and is purely just a workaround for the rust plugin system.

\section{Dependency Analysis}
% Analysis Stage
%==================
% Convert from Rust AST to our representation of Blocks and Statements
% Examine each statement for variables
% Find out the previous statement that the variable is referenced.
% This is a dependency and recorded as a relative id for the block
% Inside a block, a new DependencyTree is created
% The function name, DependencyTree and some other meta data is stored into an list.
% This is repeated for all the functions which have the annotation

% Once all the function have been analysed.
% Each dependency tree is converted into an EncodedDependencyTree by taking the StmtID of each statement.
% StmtID is the span.lo().0 and span.hi().0 which refers to the byte in the original source code.

% All the EncodedDependencyTree's and function meta data is saved into a JSON file
In the design section of the report, the dependency analysis algorithm takes in a block and examines it statement by statement to extract out the variables that are used. Actually doing this in the compiler plugin required a lot more effort than it seems on the face of it. The compiler calls a function in the plugin for each annotated function. To get the \rustc{Block} struct out of this requires expanding the \rustc{FnKind} enum. A \rustc{Block} contains a list of statements (\rustc{Stmt}). The \rustc{Stmt} struct contains a \rustc{StmtKind} enum. This describes what kind of statement it is, either a local variable binding, an unexpanded macro, or an expression ending with or without a semicolon. For the variable binding, a \rustc{Local} struct is given which contains a \rustc{Path} representing the variable name. Some variables will be assigned a value at creation and this is represented as an \rustc{Expr} struct. Unexpanded macros contain some other types which represent the arguments to the macro, but I did not end up going any deeper into this. Statements which are expression with or without a semicolon will give an \rustc{Expr} struct. Similar to the \rustc{Stmt} struct, the \rustc{Expr} struct contains a \rustc{ExprKind} enum which represents the $39$ different types of expressions. Most of these options contain another \rustc{Expr}, but some contain other types like a \rustc{Pat} which is the second way a variable can be represented. Almost all of the different cases in \rustc{ExprKind} had to be dealt with to fully explore the tree and extract all the variables a statement uses (its environment).

Each statement is converted into our representation of the AST so that information can be stored about the dependencies. The original design used two types, a expr to represent a single statement and a block to represent a list of exprs and blocks. This design does not deal a \rustc{ExprKind} which contains a \rustc{Block} properly (i.e. a for loop). My first idea was to split the \rustc{Stmt} into a expr and a block and set the block to depend on the expr. This seemed to work for the dependency analysis stage, but not for the reconstruction stage. It was difficult to distinguish which block is the contents of the \rustc{ExprKind} if an external block was also dependent on the expr. I created a third type called exprblock which contains one expr and a list of blocks (as if-else statements will require more than one block). Once all the statements for a function are converted into our representation, and each statement had an environment, then the environments could be matched up as described in Algorithm \ref{alg:dependency-analysis}. The statement ID stored is relative to the block of all of the dependencies.

\todo{Two environments so two lets with the same variable are not dependent.} Originally only the dependency ids were going to be added to our representation of the AST, but I later realised that I should also store the environment. Later still I realised that just using one environment had a flaw which includes two environments containing which variables the statement requires and produces.

\section{Modification Stage}
% Modification Stage
%==================
% First part of analysis stage is repeated for the modification stage.
% Modification stage does not have marcos expanded, and so some dependencies would be missed.
% The EncodedDependencyTree is loaded from the JSON file which should include the dependency of the expanded macros.
% The EncodedDependencyTree is merged with the DependencyTree from the Modification stage so that unexpanded macros have dependencies.
\subsection{Shared File}
\todo{Shared file between stages. StatementID that is consistent between compiles. Tried merging dependencies then replacing dependencies}

Once all functions have been analysed, the DependencyTree is converted into an EncodedDependencyTree. The code part of the converted statement is converted into a statement id. The statement ID is represented as a pair of numbers \texttt{(span.lo().0, span.hi().0)}, which relate to the byte location of the source code. This will remain consistent between compile runs, whereas the NodeID does not. All EncodedDependencyTrees and function meta data is stored into a JSON file using \texttt{serde\_json}.

The plugin detects the JSON file and loads it. This is stored as a shared state between different functions.

The first part of the dependency analysis is repeated for the syntax extension plugin this time. In later section of the design, we need access to the pure AST. There is no (easy) way for the AST to be store into a JSON file and recreated into structs that I could find. The reason that we use the linter plugin is so that we can see the dependencies hidden inside macros.

The dependencies are merged function by function from the shared state so that unexpanded macros get the missing dependencies. The dependencies of Statements that have the same StmtID are merged together.



\subsection{Scheduler}
Once the dependency analysis is complete, the scheduler takes the dependency tree and works out a schedule. All relative dependency ids are converted into StmtIDs. The idea around the scheduling algorithm is Maximum Spanning Trees. All statements that have no dependencies can be started at the very beginning. All remaining statements wait for all their dependencies to be put into the schedule. Once all the dependencies for a statement are added, this statement is selected as the next one to add to the schedule. As each statement requires all of its dependencies before it can be executed, it should be scheduled to run after the slowest dependency. This should minimise the amount of time that the statement has to wait for its dependencies. Synclines are created for all the remaining dependencies so that all dependencies are met. Each block gets its own schedule.

\todo{Add environment to syncline}

\subsection{Reconstructor}
\todo{Reconstructor. Struggle of creating new statements with specific StatementIDs. Compiler bug that requires me to recompile for a third time}
\todo{Return types}
All parts of the reconstructor algorithm takes part in the second compile.
% Takes the schedule of a function and converts it back into real (parallelised) code

\begin{comment}
\begin{code}
\begin{minted}{rust}
let a; // Local without init
a = {
    let b = vec![1,2,3]; // Local with init
    println!("{:?}", b); // Mac
    b.len() // Expr
}; // Semi
\end{minted}
\caption{Example showing different StmtKinds}
\end{code}
\end{comment}
